{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished imports\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "import tensorflow.keras.callbacks as callback\n",
    "print(\"Finished imports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported MNIST dataset\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
    "y_train = tf.keras.utils.to_categorical(y_train,  10)\n",
    "print(\"Imported MNIST dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last most accurate network in Nielsen's NN&DL\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(20, (5, 5), input_shape=(28, 28, 1), activation=\"relu\")) #Convolutional layer\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(40, (5, 5), activation=\"relu\"))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Flatten())\n",
    "# Dropout (.5) doesn't play nice here\n",
    "model2.add(Dense(1000, activation=\"relu\")) #Fully connnected layer\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(1000, activation=\"relu\"))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model2.compile(optimizer=tf.keras.optimizers.SGD(0.03),\n",
    "               loss=\"mse\", \n",
    "               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 12s 298us/step - loss: 0.1551 - acc: 0.2138 - val_loss: 0.0924 - val_acc: 0.5294\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 12s 298us/step - loss: 0.1800 - acc: 0.0988 - val_loss: 0.1799 - val_acc: 0.1008\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 12s 299us/step - loss: 0.1647 - acc: 0.1718 - val_loss: 0.1468 - val_acc: 0.2579\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 12s 301us/step - loss: 0.1795 - acc: 0.1019 - val_loss: 0.1795 - val_acc: 0.1025\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 12s 299us/step - loss: 0.1504 - acc: 0.2402 - val_loss: 0.0898 - val_acc: 0.5399\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 12s 306us/step - loss: 0.1727 - acc: 0.1341 - val_loss: 0.1611 - val_acc: 0.1915\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 12s 307us/step - loss: 0.1784 - acc: 0.1066 - val_loss: 0.1613 - val_acc: 0.1906\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 12s 312us/step - loss: 0.1792 - acc: 0.1035 - val_loss: 0.1795 - val_acc: 0.1025\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 13s 315us/step - loss: 0.1429 - acc: 0.2758 - val_loss: 0.0767 - val_acc: 0.6039\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 13s 316us/step - loss: 0.1801 - acc: 0.0989 - val_loss: 0.1800 - val_acc: 0.0999\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 13s 318us/step - loss: 0.1806 - acc: 0.0960 - val_loss: 0.1801 - val_acc: 0.0995\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 13s 321us/step - loss: 0.0980 - acc: 0.4925 - val_loss: 0.0324 - val_acc: 0.8292\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 13s 323us/step - loss: 0.1403 - acc: 0.2878 - val_loss: 0.0788 - val_acc: 0.5969\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 13s 327us/step - loss: 0.1636 - acc: 0.1784 - val_loss: 0.1647 - val_acc: 0.1755\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 14s 343us/step - loss: 0.1509 - acc: 0.2355 - val_loss: 0.0881 - val_acc: 0.5394\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 13s 335us/step - loss: 0.1760 - acc: 0.1180 - val_loss: 0.1587 - val_acc: 0.2026\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 13s 327us/step - loss: 0.1743 - acc: 0.1265 - val_loss: 0.1635 - val_acc: 0.1811\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 13s 333us/step - loss: 0.1791 - acc: 0.1037 - val_loss: 0.1786 - val_acc: 0.1070\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 13s 330us/step - loss: 0.1774 - acc: 0.1091 - val_loss: 0.1785 - val_acc: 0.1073\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 13s 333us/step - loss: 0.1796 - acc: 0.1013 - val_loss: 0.1807 - val_acc: 0.0966\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 14s 339us/step - loss: 0.1399 - acc: 0.2931 - val_loss: 0.1062 - val_acc: 0.4638\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 13s 337us/step - loss: 0.1701 - acc: 0.1416 - val_loss: 0.1259 - val_acc: 0.3554\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 14s 342us/step - loss: 0.1795 - acc: 0.1021 - val_loss: 0.1795 - val_acc: 0.1025\n",
      "Train on 40000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 14s 339us/step - loss: 0.1801 - acc: 0.0985 - val_loss: 0.1807 - val_acc: 0.0966\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 25):\n",
    "    model2 = Sequential()\n",
    "    model2.add(Conv2D(20, (5, 5), input_shape=(28, 28, 1), activation=\"relu\")) #Convolutional layer\n",
    "    model2.add(MaxPooling2D((2, 2)))\n",
    "    model2.add(Conv2D(40, (5, 5), activation=\"relu\"))\n",
    "    model2.add(MaxPooling2D((2, 2)))\n",
    "    model2.add(Flatten())\n",
    "    # Dropout (.5) doesn't play nice here\n",
    "    model2.add(Dense(1000, activation=\"relu\")) #Fully connnected layer\n",
    "    model2.add(Dropout(0.5))\n",
    "    model2.add(Dense(1000, activation=\"relu\"))\n",
    "    model2.add(Dropout(0.5))\n",
    "    model2.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    model2.compile(optimizer=tf.keras.optimizers.SGD(0.03),\n",
    "                   loss=\"mse\", \n",
    "                   metrics=[\"accuracy\"])\n",
    "    model2.fit(x_train, y_train, batch_size=32, epochs=1, validation_split=0.3333333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run up to here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49999 samples, validate on 10001 samples\n",
      "Epoch 1/100\n",
      "49999/49999 [==============================] - 6s 119us/step - loss: 0.0536 - acc: 0.7096 - val_loss: 0.0334 - val_acc: 0.8661\n",
      "Epoch 2/100\n",
      "49999/49999 [==============================] - 5s 92us/step - loss: 0.0293 - acc: 0.8710 - val_loss: 0.0239 - val_acc: 0.8956\n",
      "Epoch 3/100\n",
      "49999/49999 [==============================] - 5s 104us/step - loss: 0.0231 - acc: 0.8913 - val_loss: 0.0196 - val_acc: 0.9109\n",
      "Epoch 4/100\n",
      "49999/49999 [==============================] - 6s 120us/step - loss: 0.0200 - acc: 0.9016 - val_loss: 0.0177 - val_acc: 0.9111\n",
      "Epoch 5/100\n",
      "49999/49999 [==============================] - 5s 103us/step - loss: 0.0183 - acc: 0.9085 - val_loss: 0.0162 - val_acc: 0.9185\n",
      "Epoch 6/100\n",
      "49999/49999 [==============================] - 5s 101us/step - loss: 0.0169 - acc: 0.9136 - val_loss: 0.0150 - val_acc: 0.9229\n",
      "Epoch 7/100\n",
      "49999/49999 [==============================] - 5s 102us/step - loss: 0.0159 - acc: 0.9173 - val_loss: 0.0147 - val_acc: 0.9235\n",
      "Epoch 8/100\n",
      "49999/49999 [==============================] - 5s 97us/step - loss: 0.0150 - acc: 0.9221 - val_loss: 0.0140 - val_acc: 0.9275\n",
      "Epoch 9/100\n",
      "49999/49999 [==============================] - 5s 102us/step - loss: 0.0144 - acc: 0.9255 - val_loss: 0.0132 - val_acc: 0.9299\n",
      "Epoch 10/100\n",
      "49999/49999 [==============================] - 5s 98us/step - loss: 0.0138 - acc: 0.9270 - val_loss: 0.0131 - val_acc: 0.9288\n",
      "Epoch 11/100\n",
      "49999/49999 [==============================] - 5s 97us/step - loss: 0.0134 - acc: 0.9285 - val_loss: 0.0124 - val_acc: 0.9340\n",
      "Epoch 12/100\n",
      "49999/49999 [==============================] - 5s 101us/step - loss: 0.0130 - acc: 0.9308 - val_loss: 0.0122 - val_acc: 0.9343\n",
      "Epoch 13/100\n",
      "49999/49999 [==============================] - 5s 97us/step - loss: 0.0127 - acc: 0.9330 - val_loss: 0.0121 - val_acc: 0.9354\n",
      "Epoch 14/100\n",
      "49999/49999 [==============================] - 5s 97us/step - loss: 0.0123 - acc: 0.9345 - val_loss: 0.0117 - val_acc: 0.9369\n",
      "Epoch 15/100\n",
      "49999/49999 [==============================] - 5s 102us/step - loss: 0.0119 - acc: 0.9370 - val_loss: 0.0114 - val_acc: 0.9382\n",
      "Epoch 16/100\n",
      "49999/49999 [==============================] - 5s 96us/step - loss: 0.0117 - acc: 0.9364 - val_loss: 0.0115 - val_acc: 0.9393\n",
      "Epoch 17/100\n",
      "49999/49999 [==============================] - 5s 95us/step - loss: 0.0115 - acc: 0.9389 - val_loss: 0.0110 - val_acc: 0.9403\n",
      "Epoch 18/100\n",
      "49999/49999 [==============================] - 5s 99us/step - loss: 0.0112 - acc: 0.9398 - val_loss: 0.0109 - val_acc: 0.9429\n",
      "Epoch 19/100\n",
      "49999/49999 [==============================] - 5s 100us/step - loss: 0.0110 - acc: 0.9410 - val_loss: 0.0107 - val_acc: 0.9391\n",
      "Epoch 20/100\n",
      "49999/49999 [==============================] - 5s 97us/step - loss: 0.0109 - acc: 0.9421 - val_loss: 0.0108 - val_acc: 0.9417\n",
      "Epoch 21/100\n",
      "49999/49999 [==============================] - 5s 99us/step - loss: 0.0107 - acc: 0.9433 - val_loss: 0.0104 - val_acc: 0.9423\n",
      "Epoch 22/100\n",
      "49999/49999 [==============================] - 5s 101us/step - loss: 0.0105 - acc: 0.9437 - val_loss: 0.0102 - val_acc: 0.9438\n",
      "Epoch 23/100\n",
      "49999/49999 [==============================] - 5s 97us/step - loss: 0.0103 - acc: 0.9454 - val_loss: 0.0100 - val_acc: 0.9467\n",
      "Epoch 24/100\n",
      "49999/49999 [==============================] - 5s 97us/step - loss: 0.0102 - acc: 0.9451 - val_loss: 0.0099 - val_acc: 0.9481\n",
      "Epoch 25/100\n",
      "49999/49999 [==============================] - 5s 101us/step - loss: 0.0101 - acc: 0.9460 - val_loss: 0.0099 - val_acc: 0.9453\n",
      "Epoch 26/100\n",
      "49999/49999 [==============================] - 5s 103us/step - loss: 0.0098 - acc: 0.9480 - val_loss: 0.0099 - val_acc: 0.9458\n",
      "Epoch 27/100\n",
      "49999/49999 [==============================] - 5s 96us/step - loss: 0.0098 - acc: 0.9478 - val_loss: 0.0095 - val_acc: 0.9473\n",
      "Epoch 28/100\n",
      "49999/49999 [==============================] - 5s 94us/step - loss: 0.0095 - acc: 0.9501 - val_loss: 0.0094 - val_acc: 0.9499\n",
      "Epoch 29/100\n",
      "49999/49999 [==============================] - 4s 85us/step - loss: 0.0095 - acc: 0.9505 - val_loss: 0.0096 - val_acc: 0.9483\n",
      "Epoch 30/100\n",
      "49999/49999 [==============================] - 4s 85us/step - loss: 0.0094 - acc: 0.9508 - val_loss: 0.0096 - val_acc: 0.9465\n",
      "Epoch 31/100\n",
      "49999/49999 [==============================] - 4s 85us/step - loss: 0.0093 - acc: 0.9505 - val_loss: 0.0092 - val_acc: 0.9479\n",
      "Epoch 32/100\n",
      "49999/49999 [==============================] - 4s 89us/step - loss: 0.0093 - acc: 0.9507 - val_loss: 0.0094 - val_acc: 0.9495\n",
      "Epoch 33/100\n",
      "49999/49999 [==============================] - 4s 85us/step - loss: 0.0090 - acc: 0.9528 - val_loss: 0.0093 - val_acc: 0.9510\n",
      "Epoch 34/100\n",
      "49999/49999 [==============================] - 4s 85us/step - loss: 0.0089 - acc: 0.9524 - val_loss: 0.0091 - val_acc: 0.9506\n",
      "Epoch 35/100\n",
      "49999/49999 [==============================] - 4s 86us/step - loss: 0.0088 - acc: 0.9533 - val_loss: 0.0091 - val_acc: 0.9515\n",
      "Epoch 36/100\n",
      "49999/49999 [==============================] - 4s 89us/step - loss: 0.0088 - acc: 0.9532 - val_loss: 0.0088 - val_acc: 0.9497\n",
      "Epoch 37/100\n",
      "49999/49999 [==============================] - 4s 85us/step - loss: 0.0086 - acc: 0.9545 - val_loss: 0.0090 - val_acc: 0.9507\n",
      "Epoch 38/100\n",
      "49999/49999 [==============================] - 4s 85us/step - loss: 0.0086 - acc: 0.9550 - val_loss: 0.0087 - val_acc: 0.9520\n",
      "Epoch 39/100\n",
      "49999/49999 [==============================] - 4s 89us/step - loss: 0.0084 - acc: 0.9555 - val_loss: 0.0089 - val_acc: 0.9505\n",
      "Epoch 40/100\n",
      "49999/49999 [==============================] - 4s 86us/step - loss: 0.0086 - acc: 0.9549 - val_loss: 0.0089 - val_acc: 0.9501\n",
      "Epoch 41/100\n",
      "49999/49999 [==============================] - 4s 85us/step - loss: 0.0083 - acc: 0.9558 - val_loss: 0.0086 - val_acc: 0.9524\n",
      "Epoch 42/100\n",
      "49999/49999 [==============================] - 4s 85us/step - loss: 0.0081 - acc: 0.9574 - val_loss: 0.0086 - val_acc: 0.9528\n",
      "Epoch 43/100\n",
      "49999/49999 [==============================] - 4s 90us/step - loss: 0.0081 - acc: 0.9575 - val_loss: 0.0086 - val_acc: 0.9529\n",
      "Epoch 44/100\n",
      "49999/49999 [==============================] - 4s 85us/step - loss: 0.0080 - acc: 0.9583 - val_loss: 0.0085 - val_acc: 0.9531\n",
      "Epoch 45/100\n",
      "49999/49999 [==============================] - 4s 85us/step - loss: 0.0080 - acc: 0.9577 - val_loss: 0.0084 - val_acc: 0.9544\n",
      "Epoch 46/100\n",
      "49999/49999 [==============================] - 4s 86us/step - loss: 0.0080 - acc: 0.9582 - val_loss: 0.0086 - val_acc: 0.9510\n",
      "Epoch 47/100\n",
      "49999/49999 [==============================] - 4s 89us/step - loss: 0.0079 - acc: 0.9586 - val_loss: 0.0086 - val_acc: 0.9516\n",
      "Epoch 48/100\n",
      "49999/49999 [==============================] - 4s 85us/step - loss: 0.0078 - acc: 0.9591 - val_loss: 0.0083 - val_acc: 0.9533\n",
      "Epoch 49/100\n",
      "49999/49999 [==============================] - 4s 85us/step - loss: 0.0078 - acc: 0.9591 - val_loss: 0.0084 - val_acc: 0.9548\n",
      "Epoch 50/100\n",
      "49999/49999 [==============================] - 4s 88us/step - loss: 0.0078 - acc: 0.9595 - val_loss: 0.0084 - val_acc: 0.9554\n",
      "Epoch 51/100\n",
      "49999/49999 [==============================] - 4s 87us/step - loss: 0.0076 - acc: 0.9594 - val_loss: 0.0082 - val_acc: 0.9547\n",
      "Epoch 52/100\n",
      "49999/49999 [==============================] - 4s 85us/step - loss: 0.0076 - acc: 0.9603 - val_loss: 0.0082 - val_acc: 0.9553\n",
      "Epoch 53/100\n",
      "49999/49999 [==============================] - 4s 85us/step - loss: 0.0075 - acc: 0.9609 - val_loss: 0.0081 - val_acc: 0.9552\n",
      "Epoch 54/100\n",
      "49999/49999 [==============================] - 5s 90us/step - loss: 0.0074 - acc: 0.9613 - val_loss: 0.0081 - val_acc: 0.9555\n",
      "Epoch 55/100\n",
      "49999/49999 [==============================] - 4s 85us/step - loss: 0.0074 - acc: 0.9609 - val_loss: 0.0079 - val_acc: 0.9562\n",
      "Epoch 56/100\n",
      "49999/49999 [==============================] - 4s 88us/step - loss: 0.0074 - acc: 0.9613 - val_loss: 0.0079 - val_acc: 0.9563\n",
      "Epoch 57/100\n",
      "49999/49999 [==============================] - 4s 87us/step - loss: 0.0072 - acc: 0.9628 - val_loss: 0.0080 - val_acc: 0.9556\n",
      "Epoch 58/100\n",
      "49999/49999 [==============================] - 6s 122us/step - loss: 0.0072 - acc: 0.9624 - val_loss: 0.0079 - val_acc: 0.9568\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49999/49999 [==============================] - 5s 97us/step - loss: 0.0070 - acc: 0.9626 - val_loss: 0.0078 - val_acc: 0.9571\n",
      "Epoch 60/100\n",
      "49999/49999 [==============================] - 5s 91us/step - loss: 0.0071 - acc: 0.9624 - val_loss: 0.0079 - val_acc: 0.9587\n",
      "Epoch 61/100\n",
      "49999/49999 [==============================] - 5s 97us/step - loss: 0.0070 - acc: 0.9640 - val_loss: 0.0078 - val_acc: 0.9567\n",
      "Epoch 62/100\n",
      "49999/49999 [==============================] - 6s 113us/step - loss: 0.0071 - acc: 0.9630 - val_loss: 0.0077 - val_acc: 0.9577\n",
      "Epoch 63/100\n",
      "49999/49999 [==============================] - 6s 110us/step - loss: 0.0070 - acc: 0.9637 - val_loss: 0.0076 - val_acc: 0.9588\n",
      "Epoch 64/100\n",
      "49999/49999 [==============================] - 5s 109us/step - loss: 0.0068 - acc: 0.9655 - val_loss: 0.0076 - val_acc: 0.9586\n",
      "Epoch 65/100\n",
      "49999/49999 [==============================] - 5s 97us/step - loss: 0.0069 - acc: 0.9640 - val_loss: 0.0078 - val_acc: 0.9579\n",
      "Epoch 66/100\n",
      "49999/49999 [==============================] - 5s 96us/step - loss: 0.0068 - acc: 0.9653 - val_loss: 0.0075 - val_acc: 0.9603\n",
      "Epoch 67/100\n",
      "49999/49999 [==============================] - 5s 100us/step - loss: 0.0068 - acc: 0.9645 - val_loss: 0.0077 - val_acc: 0.9568\n",
      "Epoch 68/100\n",
      "49999/49999 [==============================] - 5s 98us/step - loss: 0.0067 - acc: 0.9649 - val_loss: 0.0076 - val_acc: 0.9595\n",
      "Epoch 69/100\n",
      "49999/49999 [==============================] - 5s 100us/step - loss: 0.0066 - acc: 0.9658 - val_loss: 0.0074 - val_acc: 0.9601\n",
      "Epoch 70/100\n",
      "49999/49999 [==============================] - 5s 98us/step - loss: 0.0066 - acc: 0.9662 - val_loss: 0.0074 - val_acc: 0.9600\n",
      "Epoch 71/100\n",
      "49999/49999 [==============================] - 5s 97us/step - loss: 0.0066 - acc: 0.9663 - val_loss: 0.0075 - val_acc: 0.9590\n",
      "Epoch 72/100\n",
      "41952/49999 [========================>.....] - ETA: 0s - loss: 0.0066 - acc: 0.9666"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-58e1cf5bbb11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mse\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1666667\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1361\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    262\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2912\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2914\u001b[1;33m     \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2915\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2916\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_test = Sequential()\n",
    "model_test.add(Flatten(input_shape=(28,28,1)))\n",
    "model_test.add(Dense(100, activation=\"sigmoid\"))\n",
    "model_test.add(Dense(10, activation=\"sigmoid\"))\n",
    "model_test.compile(optimizer=tf.keras.optimizers.SGD(0.1), loss=\"mse\",metrics=[\"accuracy\"])\n",
    "\n",
    "model_test.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.1666667)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(20, (5, 5), input_shape=(28, 28, 1), activation=\"relu\"))\n",
    "model1.add(MaxPooling2D((2, 2)))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(100, activation=\"relu\"))\n",
    "model1.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
