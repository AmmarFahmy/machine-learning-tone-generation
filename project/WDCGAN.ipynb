{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "36af9c2edba178f04e989ca2a5935878caf7b0c4",
    "colab": {},
    "colab_type": "code",
    "id": "YfIk2es3hJEd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1002983\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished imports\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# Import TensorFlow >= 1.10 and enable eager execution\n",
    "import tensorflow as tf\n",
    "\n",
    "import librosa\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import imageio\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import simpleaudio as sa\n",
    "import math\n",
    "from IPython import display\n",
    "\n",
    "print(\"Finished imports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playAudio(audio, sr):\n",
    "    audio = audio.astype(np.int16)\n",
    "    play_obj = sa.play_buffer(audio, 1, 2, sr)\n",
    "    play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "54b14c2eb0796084f10136c5668a1be53875fd89",
    "colab": {},
    "colab_type": "code",
    "id": "u_2z-B3piVsw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in c:\\users\\1002983\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (2.3.0)\n"
     ]
    }
   ],
   "source": [
    "# to generate gifs\n",
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0b37e5e63b1cc242f5b7cb8988bcbf4a1155d280",
    "colab_type": "text",
    "id": "THY-sZMiQ4UV"
   },
   "source": [
    "## Write the generator and discriminator models\n",
    "\n",
    "* **Generator** \n",
    "  * It is responsible for **creating convincing images that are good enough to fool the discriminator**.\n",
    "  * It consists of Conv2DTranspose (Upsampling) layers. We start with a fully connected layer and upsample the image 2 times so as to reach the desired image size (mnist image size) which is (28, 28, 1). \n",
    "  * We use **leaky relu** activation except for the **last layer** which uses **tanh** activation.\n",
    "  \n",
    "* **Discriminator**\n",
    "  * **The discriminator is responsible for classifying the fake images from the real images.**\n",
    "  * In other words, the discriminator is given generated images (from the generator) and the real MNIST images. The job of the discriminator is to classify these images into fake (generated) and real (MNIST images).\n",
    "  * **Basically the generator should be good enough to fool the discriminator that the generated images are real**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "c6cfcdfef1caf6dd8cd6e197105d47f314b6452a",
    "colab": {},
    "colab_type": "code",
    "id": "S4PIDhoDLbsZ"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1689\n",
    "BATCH_SIZE = 3\n",
    "NUM_CORES = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Reading spectrograms from TFRecord file, making dataset\n",
    "read_features = {\n",
    "    'note': tf.FixedLenFeature([], dtype=tf.int64),\n",
    "    'note_str': tf.FixedLenFeature([], dtype=tf.string),\n",
    "    'instrument': tf.FixedLenFeature([], dtype=tf.int64),\n",
    "    'instrument_str': tf.FixedLenFeature([], dtype=tf.string),\n",
    "    'pitch': tf.FixedLenFeature([], dtype=tf.int64),\n",
    "    'velocity': tf.FixedLenFeature([], dtype=tf.int64),\n",
    "    'sample_rate': tf.FixedLenFeature([], dtype=tf.int64),\n",
    "    'spectrogram': tf.FixedLenFeature([258300], dtype=float),\n",
    "    'instrument_family': tf.FixedLenFeature([], dtype=tf.int64),\n",
    "    'instrument_family_str': tf.FixedLenFeature([], dtype=tf.string),\n",
    "    'instrument_source': tf.FixedLenFeature([], dtype=tf.int64),\n",
    "    'instrument_source_str': tf.FixedLenFeature([], dtype=tf.string)\n",
    "}\n",
    "\n",
    "def _map(raw_data):\n",
    "    return tf.reshape(tf.parse_single_example(serialized=raw_data, features=read_features)['spectrogram'], [1025, 126, 2])\n",
    "\n",
    "specs = tf.data.TFRecordDataset(\"spectrograms.tfrecord\")\n",
    "specs = specs.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=BUFFER_SIZE))\n",
    "specs = specs.map(map_func=_map, num_parallel_calls=NUM_CORES)\n",
    "specs = specs.batch(batch_size=3)\n",
    "specs = specs.prefetch(buffer_size=BUFFER_SIZE)\n",
    "\n",
    "print(\"\\nDone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "f50d15ea77525e355d3b1cca08240a3d920fec3a",
    "colab": {},
    "colab_type": "code",
    "id": "VGLbvBEmjK0a"
   },
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(41*7*128, use_bias=False)\n",
    "        self.batchnorm1 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)\n",
    "        self.batchnorm2 = tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "        self.conv2 = tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(1, 2), padding='same', use_bias=False)\n",
    "        self.batchnorm3 = tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "        self.conv3 = tf.keras.layers.Conv2DTranspose(32, (5, 5), strides=(5, 3), padding='same', use_bias=False)\n",
    "        self.batchnorm4 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv4 = tf.keras.layers.Conv2DTranspose(2, (5, 5), strides=(5, 3), padding='same', use_bias=False)\n",
    "        \n",
    "    def call(self, x, training=True):\n",
    "        x = self.fc1(x)\n",
    "        x = self.batchnorm1(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        x = tf.reshape(x, shape=(-1, 41, 7, 128))\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm2(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm3(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm4(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        x = tf.nn.tanh(self.conv4(x))  \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "92507e1426e5d24567fc5ff7e982a512826046f6",
    "colab": {},
    "colab_type": "code",
    "id": "bkOfJxk5j5Hi"
   },
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')\n",
    "        self.dropout = tf.keras.layers.Dropout(0.3)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, x, training=True):\n",
    "        x = tf.nn.leaky_relu(self.conv1(x))\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = tf.nn.leaky_relu(self.conv2(x))\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "546fbaed647277db33477433fab8de5e09b8507c",
    "colab_type": "text",
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "## Define the loss functions and the optimizer\n",
    "\n",
    "* **Discriminator loss**\n",
    "  * The discriminator loss function takes 2 inputs; **real images, generated images**\n",
    "  * real_loss is a sigmoid cross entropy loss of the **real images** and an **array of ones (since these are the real images)**\n",
    "  * generated_loss is a sigmoid cross entropy loss of the **generated images** and an **array of zeros (since these are the fake images)**\n",
    "  * Then the total_loss is the sum of real_loss and the generated_loss\n",
    "  \n",
    "* **Generator loss**\n",
    "  * It is a sigmoid cross entropy loss of the generated images and an **array of ones**\n",
    "  \n",
    "\n",
    "* The discriminator and the generator optimizers are different since we will train them separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "47ae70cfe471b80ac827a5772bcba07ec890450f",
    "colab": {},
    "colab_type": "code",
    "id": "wkMNfBWlT-PV"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, generated_output):\n",
    "    return real_output - generated_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "df009f9802ad5e4ecca74e113a4501340029bba3",
    "colab": {},
    "colab_type": "code",
    "id": "90BIcCKcDMxz"
   },
   "outputs": [],
   "source": [
    "def generator_loss(generated_output):\n",
    "    return -1*generated_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b18f2143da7577f6bdc515c26ce48fa1b7e3c91",
    "colab_type": "text",
    "id": "mWtinsGDPJlV"
   },
   "source": [
    "## Checkpoints (Object-based saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "b3d909e947bc7fcba6dd2b2851f67396176cdbc2",
    "colab": {},
    "colab_type": "code",
    "id": "CA1w-7s2POEy"
   },
   "outputs": [],
   "source": [
    "# checkpoint_dir = './training_checkpoints'\n",
    "# checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "# checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "#                                  discriminator_optimizer=discriminator_optimizer,\n",
    "#                                  generator=generator,\n",
    "#                                  discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3bc7f14b0173073ee003c2f6e8c3b1a3ee5d06ce",
    "colab_type": "text",
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "## Training\n",
    "\n",
    "* We start by iterating over the dataset\n",
    "* The generator is given **noise as an input** which when passed through the generator model will output a image looking like a handwritten digit\n",
    "* The discriminator is given the **real MNIST images as well as the generated images (from the generator)**.\n",
    "* Next, we calculate the generator and the discriminator loss.\n",
    "* Then, we calculate the gradients of loss with respect to both the generator and the discriminator variables (inputs) and apply those to the optimizer.\n",
    "\n",
    "## Generate Images\n",
    "\n",
    "* After training, its time to generate some images!\n",
    "* We start by creating noise array as an input to the generator\n",
    "* The generator will then convert the noise into handwritten images.\n",
    "* Last step is to plot the predictions and **voila!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "cbe0b356b41cbdeb6751dfde003e8590cb68586b",
    "colab": {},
    "colab_type": "code",
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 150\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement of the gan.\n",
    "random_vector_for_generation = tf.random_normal([num_examples_to_generate,\n",
    "                                                 noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "16478afa6311040cd8132a2c1980652a656618e6",
    "colab": {},
    "colab_type": "code",
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    # make sure the training parameter is set to False because we\n",
    "    # don't want to train the batchnorm layer when doing inference.\n",
    "    predictions = sess.run(model(test_input, training=False))\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5, cmap=\"magma\", origin=\"lower\", aspect=\"auto\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildgraph():\n",
    "    with tf.variable_scope('gen'):\n",
    "        generator = Generator()\n",
    "    with tf.variable_scope('disc'):\n",
    "        discriminator = Discriminator()\n",
    "    noise = tf.random_normal([BATCH_SIZE, noise_dim])\n",
    "    \n",
    "    images = tf.placeholder(tf.float32, shape=[BATCH_SIZE, 1025, 126, 2], name='images')\n",
    "    \n",
    "    gen_opt = tf.contrib.layers.optimize_loss(\n",
    "        tf.reduce_mean(generator_loss(discriminator(generator(noise, training=True), training=True))), \n",
    "        None, learning_rate=1e-4, optimizer='Adam', variables=generator.trainable_variables)\n",
    "    with tf.control_dependencies([gen_opt]):\n",
    "        gen_opt = tf.tuple([tf.assign(var, tf.clip_by_value(var, -0.01, 0.01)) \n",
    "                            for var in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='gen')])\n",
    "        \n",
    "    disc_opt = tf.contrib.layers.optimize_loss(\n",
    "        tf.reduce_mean(discriminator_loss(\n",
    "            discriminator(images, training=True), discriminator(generator(noise, training=True), training=True))),\n",
    "        None, learning_rate=1e-4, optimizer='Adam', variables=discriminator.trainable_variables)\n",
    "    with tf.control_dependencies([disc_opt]):\n",
    "        disc_opt = tf.tuple([tf.assign(var, tf.clip_by_value(var, -0.01, 0.01)) \n",
    "                             for var in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='disc')])\n",
    "    \n",
    "    return generator, gen_opt, disc_opt, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "ac0e304af171a8d292728d743ae39e464da065cf",
    "colab": {},
    "colab_type": "code",
    "id": "2M7LmLtGEMQJ"
   },
   "outputs": [],
   "source": [
    "def train(batch, epochs, noise_dim, gen_opt, disc_opt, images):  \n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        runOneEpoch(batch, noise_dim, gen_opt, disc_opt, images)\n",
    "        print ('Time taken for epoch {} is {} sec'.format(epoch + 1,\n",
    "                                                          time.time()-start))\n",
    "  # generating after the final epoch\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                           -1,\n",
    "                           random_vector_for_generation)\n",
    "    \n",
    "def runOneEpoch(batch, noise_dim, gen_opt, disc_opt, images):\n",
    "    for num in range(math.ceil(BUFFER_SIZE/BATCH_SIZE)):\n",
    "        if(num % 5 == 4):\n",
    "            sess.run(gen_opt, feed_dict={images: sess.run(batch)})\n",
    "        else:\n",
    "            sess.run(disc_opt, feed_dict={images: sess.run(batch)})\n",
    "        print(\"Finished {} out of {}\".format(num*3+3, math.ceil(BUFFER_SIZE)), end='\\r')\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                           -1,\n",
    "                           random_vector_for_generation)\n",
    "\n",
    "    # saving (checkpoint) the model every 15 epochs\n",
    "    #if (epoch + 1) % 15 == 0:\n",
    "        #checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time taken {} sec'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testAudio(batch):\n",
    "    while(True):\n",
    "        spec = sess.run(batch)[0]\n",
    "        mag = spec[:, :, 0]\n",
    "        angles = spec[:, :, 1]\n",
    "        mag = ((mag+1)/2)*48-32\n",
    "        angles = angles*math.pi\n",
    "        ft =(np.exp(mag)-1.2664166e-14)*np.exp(1j*angles)\n",
    "        newaudio = librosa.istft(ft, 512, 2048)\n",
    "        print('Generated audio')\n",
    "        print('Interval of audio: [{}, {}]'.format(np.amin(newaudio), np.amax(newaudio)))\n",
    "        playAudio(newaudio, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "446c1e4d2462906cc5ed888104e549ac86b476b2",
    "colab": {},
    "colab_type": "code",
    "id": "Ly3UN0SLLY2l",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generator, gen_opt, disc_opt, images = buildgraph()\n",
    "iterator = specs.make_one_shot_iterator()\n",
    "batch = iterator.get_next()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "if(not(os.path.isdir(\"checkpoints\"))):\n",
    "    saver.save(sess, \"checkpoints/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/model\n",
      "Finished 993 out of 1689\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-8f30bcf43c40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"checkpoints/model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mrunOneEpoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisc_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"checkpoints/model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-09a1353666dc>\u001b[0m in \u001b[0;36mrunOneEpoch\u001b[1;34m(batch, noise_dim, gen_opt, disc_opt, images)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisc_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Finished {} out of {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBUFFER_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    saver.restore(sess, \"checkpoints/model\")\n",
    "    runOneEpoch(batch, noise_dim, gen_opt, disc_opt, images)\n",
    "    saver.save(sess, \"checkpoints/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_save_images(generator, -1, random_vector_for_generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9e5c596190985b8954f9ba6bec73bc504a0f9465",
    "colab_type": "text",
    "id": "rfM4YcPVPkNO"
   },
   "source": [
    "## Restore the latest checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "0476d178527341a5d84219855f70f44a161f5c7c",
    "colab": {},
    "colab_type": "code",
    "id": "XhXsd0srPo8c"
   },
   "outputs": [],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "601fa61b7f04044bc352d8d13f9dfce246080614",
    "colab_type": "text",
    "id": "P4M_vIbUi7c0"
   },
   "source": [
    "## Display an image using the epoch number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3d21c33fa4fecb4c72ed49e0ae0b9f6abee75dba",
    "colab": {},
    "colab_type": "code",
    "id": "WfO5wCdclHGL"
   },
   "outputs": [],
   "source": [
    "# def display_image(epoch_no):\n",
    "#     return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0232942a4f22dedcecae086388e4722fb4906ace",
    "colab": {},
    "colab_type": "code",
    "id": "5x3q9_Oe5q0A"
   },
   "outputs": [],
   "source": [
    "# display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "198958796c1208b11522c22e4742eb1820a35389",
    "colab_type": "text",
    "id": "NywiH3nL8guF"
   },
   "source": [
    "## Generate a GIF of all the saved images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "11fdb14d3158b74c7f5676863c9d81fb1447756e",
    "colab_type": "text",
    "id": "xmO0Dmu2WICn"
   },
   "source": [
    "<!-- TODO(markdaoust): Remove the hack when Ipython version is updated -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "18147fa7ac84aa1a5ffdb980525af8fd56583427",
    "colab": {},
    "colab_type": "code",
    "id": "IGKQgENQ8lEI"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with imageio.get_writer('dcgan.gif', mode='I') as writer:\n",
    "    filenames = glob.glob('image*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    last = -1\n",
    "    for i,filename in enumerate(filenames):\n",
    "        frame = 2*(i**0.5)\n",
    "        if round(frame) > round(last):\n",
    "            last = frame\n",
    "        else:\n",
    "            continue\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "    \n",
    "# this is a hack to display the gif inside the notebook\n",
    "os.system('cp dcgan.gif dcgan.gif.png')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f4c2daa752c2ee02dfea5ad8355b36461f438fb8",
    "colab": {},
    "colab_type": "code",
    "id": "uV0yiKpzNP1b"
   },
   "outputs": [],
   "source": [
    "# display.Image(filename=\"dcgan.gif.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0ad474f94184ff9fffeb10188b3c5024b7b9edb2",
    "colab_type": "text",
    "id": "6EEG-wePkmJQ"
   },
   "source": [
    "To downlod the animation from Colab uncomment the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a108d7fabd182f785c8adc45e33c5dd97bac348b",
    "colab": {},
    "colab_type": "code",
    "id": "4UJjSnIMOzOJ"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#files.download('dcgan.gif')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dcgan.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1eb0NOTQapkYs3X0v-zL1x5_LFKgDISnp",
     "timestamp": 1527173385672
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
